{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is a python library providing rich functionality on top of numpy. In addition to 'Excel like' tables, Pandas works well with numpy constructs and scikit-learn.\n",
    "\n",
    "For more information, the docs are available at:\n",
    "http://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Series\n",
    "\n",
    "Pandas series are like 1-dimensional numpy arrays, except that they are _labeled_, or have indices. In addition, the elements can be numeric, bools, strings, date time objects, functional objects, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can create the Pandas series from a Python list similar to Numpy\n",
    "flt_series = pd.Series( [1.0,-2, .43434] )\n",
    "flt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can also pass in a Numpy ndarray\n",
    "flt_series = pd.Series( np.random.random(5) )\n",
    "flt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dtype here is int64\n",
    "int_series = pd.Series( np.random.random_integers(0,5,5) )\n",
    "int_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dtype here is object\n",
    "str_series = pd.Series([x*2 for x in 'abcd'])\n",
    "str_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tup_series = pd.Series([(x,x+1) for x in range(4)])\n",
    "tup_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_series = pd.Series( [map for x in range(5) ])\n",
    "fun_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unlike numpy, all elements of the series do not have to be the same type\n",
    "mix_series = pd.Series( [1.0, -2, map, 'aa', np.nan])\n",
    "mix_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can use generic head() or head(# elements)\n",
    "print mix_series.head()\n",
    "print mix_series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can use generic tail() or tail(# elements)\n",
    "print mix_series.tail()\n",
    "print mix_series.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for null/Nan on each element\n",
    "mix_series.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can mix in Numpy types/operations with pandas objects\n",
    "np.any( mix_series.isnull() ) #Are ANY of the elements null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create two pd series with `a = [1,2,3,4]` and `b = [2.0, 3.0, 1.0,-1.2]`. Use `head(1)` to view only the first item of `a`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series([1,2,3,4])\n",
    "b = pd.Series([2.,3.,1.,-1.2])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Create a new pd series c = [-2, 0, 3, np.nan ]. Add `a + c`. What do you get?**\n",
    "\n",
    "Hint: you can use the `+` operator, or `np.add`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1\n",
       "1     2\n",
       "2     6\n",
       "3   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.Series([-2,0,3,np.nan])\n",
    "a + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) What does comparing the 4th element of c to np.nan evaluate to? What does imply when comparing objects with multiple nan values? Test this theory using np.all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c[3] == np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Create a pd Series where a = [1,2,3,'c',None,np.nan]. We have seen two methods so far for evaluating nans. `np.isnan` and `pd.isnull`. Evaluate both functions on `a`. What do you see?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series([1,2,3,'c',None,np.nan])\n",
    "pd.isnull(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes\n",
    "\n",
    "\n",
    "Each row of the pandas series has an index by default. In fact, you can specify your own indices \n",
    "\n",
    "Why have indices? Think of them as not only ways to conveniently label rows, but also can perform fast lookups, grouping operations, descriptive stats associated with these indices.\n",
    "\n",
    "(These are not the same as the _labels_ mentioned in supervised learning)\n",
    "\n",
    "\n",
    "Indices can be strings, integers, or even time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indSeries1 = pd.Series(np.random.random(5), \n",
    "                       index=['CA','AK','IL','IN','NY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indSeries2 = pd.Series(np.random.random(3), \n",
    "                       index=['CA','IL','WA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Really cool! Matches the indices together and adds up by index\n",
    "indSeries1 + indSeries2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datSeries = pd.Series(np.random.random(5), \n",
    "                      index=pd.date_range('2015-01-01','2015-06-01',\n",
    "                                           freq='m'))\n",
    "datSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just as a 'you can do this', if the index is a pd.date_range object,\n",
    "# then you can resample by frequency\n",
    "datSeries.resample('q') #Resample by quarter\n",
    "datSeries.resample('d') #Resample by day, will NA fill\n",
    "datSeries.resample('d', fill_method='ffill') #Resample by day, will forward will"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexes need not be strings. They can be integers as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datSeries = pd.Series(np.random.random(10),\n",
    "                     index=np.random.randint(0,1000,10))\n",
    "datSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pandas series have multiple aggregation/description methods:\n",
    "# http://pandas.pydata.org/pandas-docs/version/0.17.1/api.html#computations-descriptive-stats\n",
    "\n",
    "\n",
    "datSeries = pd.Series([1,2,5,3,5,3,2], \n",
    "                      index=[x for x in 'abcdefg'])\n",
    "datSeries.value_counts()\n",
    "datSeries.unique()\n",
    "datSeries.nunique()\n",
    "datSeries.all()\n",
    "datSeries.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create two Pandas Series with various indices. `a` is a series with `arange(5)` having indices ['CA','IL','PA','IN','WA']. `b`  is a series with `arange(5)` having indices ['CA','MN','IL','IN','WA'].**\n",
    "\n",
    "**Add `a + b`. What happens in the result?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA     0\n",
       "IL     3\n",
       "IN     6\n",
       "MN   NaN\n",
       "PA   NaN\n",
       "WA     8\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series( np.arange(5), index=['CA','IL','PA','IN','WA'])\n",
    "b = pd.Series( np.arange(5), index=['CA','MN','IL','IN','WA'])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Repeat the sum, but instead of `a+b`, try `a.add(b, fill_value=0)`. How does the result change?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    0\n",
       "IL    3\n",
       "IN    6\n",
       "MN    4\n",
       "PA    5\n",
       "WA    8\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(b,fill_value=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Create two series. `a` is `arange(1,5)` having index `['a','b','c',a']`. `b` is `arange(1,5)` having index `['a','a','c','d']`. What happens when you add `a + b`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     2\n",
       "a     3\n",
       "a     5\n",
       "a     6\n",
       "b   NaN\n",
       "c     6\n",
       "d   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series( np.arange(1,5), index=['a','b','c','a'])\n",
    "b = pd.Series( np.arange(1,5), index=['a','a','c','d'])\n",
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Basics\n",
    "DataFrames are extensions of series into tables. They can have multiple indices (rows) and columns. Think of data frames as horizontally stacked series sharing the same set of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generates default integer indexes (rows) and columns\n",
    "df = pd.DataFrame(np.random.random((5,5)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Can pass in the index (row) labels, as well as column labels instead\n",
    "df_idx = pd.date_range('2015-01-01','2015-01-05',freq='d')\n",
    "df_col = ['sun','mon','tues','wed','thurs']\n",
    "df = pd.DataFrame(np.random.random((5,5)),index=df_idx, columns=df_col)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intIndex = np.random.randint(0,100,10)\n",
    "df2 = pd.DataFrame({'a': 1.,\n",
    "                    'b': pd.Timestamp('2015-01-01'),\n",
    "                    'c': pd.Series(np.random.random(10),index=intIndex),\n",
    "                    'd': 'foo'},\n",
    "                  index=intIndex)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Multiple columnwise aggregations available. More available too! View docs\n",
    "df.head()\n",
    "df.tail()\n",
    "df.mean()\n",
    "df.min()\n",
    "df.cumsum()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns #List the column labels of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index # List the rows labels of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Unlike numpy, there is no row x column addressing using only [ ]\n",
    "#i.e. x[2,4] would work for a numpy array. x[2,4] does NOT work for a pandas dataframe\n",
    "df[0,0] #Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sun # the columns can be addressed directly as pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['sun'] # this is also valid. This returns a pd Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ ['sun'] ] # Index by label vs. array returns different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[ ['sun','mon'] ] # Can just select certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Since addressing single column returns a Series\n",
    "# We can call the Series description fn's on them\n",
    "df[ 'sun' ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['fri'] = 1.0* df['wed'] + 2.0 * df['thurs']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful here. axis is switched with pandas. Here, axis=0 refers to rows, axis=1 refers to columns. Drop requires an `index label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('fri',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('2015-01-01',axis=0) #wont work. '2015-01-01' is not the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop( pd.Timestamp('2015-01-01'), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create a dataframe where the indexes are every day from 1/1/2015 to 12/31/2015 and the columns are `calories` and `weight`. Calories should be uniform random integers from 1400 to 2000. Weight should be random normal generated having mean 180 and variance 20.**\n",
    "\n",
    "Hint: Use np.random.randint and np.random.normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>1977</td>\n",
       "      <td>174.645442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>1805</td>\n",
       "      <td>145.583461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>1631</td>\n",
       "      <td>194.649885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-04</th>\n",
       "      <td>1932</td>\n",
       "      <td>203.070020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>1904</td>\n",
       "      <td>174.151451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            calories      weight\n",
       "2015-01-01      1977  174.645442\n",
       "2015-01-02      1805  145.583461\n",
       "2015-01-03      1631  194.649885\n",
       "2015-01-04      1932  203.070020\n",
       "2015-01-05      1904  174.151451"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_index = pd.date_range('2015-01-01','2015-12-31',freq='d')\n",
    "\n",
    "df = pd.DataFrame({'calories': np.random.randint(1400,2000,len(dt_index)),\n",
    "                   'weight' : np.random.normal(180,20,len(dt_index))},\n",
    "                 index = dt_index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Add a new column `mood` to the dataframe having random uniform floats from 0 to 1.**\n",
    "\n",
    "Hint: Use np.random.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>weight</th>\n",
       "      <th>mood</th>\n",
       "      <th>mood2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>1977</td>\n",
       "      <td>174.645442</td>\n",
       "      <td>0.647517</td>\n",
       "      <td>0.137604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>1805</td>\n",
       "      <td>145.583461</td>\n",
       "      <td>0.178595</td>\n",
       "      <td>0.279707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>1631</td>\n",
       "      <td>194.649885</td>\n",
       "      <td>0.806383</td>\n",
       "      <td>0.804177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-04</th>\n",
       "      <td>1932</td>\n",
       "      <td>203.070020</td>\n",
       "      <td>0.681920</td>\n",
       "      <td>0.502303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>1904</td>\n",
       "      <td>174.151451</td>\n",
       "      <td>0.836023</td>\n",
       "      <td>0.245656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>1912</td>\n",
       "      <td>140.845166</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.275365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>1410</td>\n",
       "      <td>182.446435</td>\n",
       "      <td>0.802674</td>\n",
       "      <td>0.514477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>1452</td>\n",
       "      <td>209.108509</td>\n",
       "      <td>0.396144</td>\n",
       "      <td>0.957862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>1998</td>\n",
       "      <td>164.325011</td>\n",
       "      <td>0.250750</td>\n",
       "      <td>0.406285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-10</th>\n",
       "      <td>1573</td>\n",
       "      <td>157.392585</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.814814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-11</th>\n",
       "      <td>1539</td>\n",
       "      <td>195.110532</td>\n",
       "      <td>0.886354</td>\n",
       "      <td>0.275565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-12</th>\n",
       "      <td>1493</td>\n",
       "      <td>220.320826</td>\n",
       "      <td>0.734026</td>\n",
       "      <td>0.766214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-13</th>\n",
       "      <td>1725</td>\n",
       "      <td>165.238119</td>\n",
       "      <td>0.777186</td>\n",
       "      <td>0.394749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-14</th>\n",
       "      <td>1832</td>\n",
       "      <td>187.827453</td>\n",
       "      <td>0.538420</td>\n",
       "      <td>0.764104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-15</th>\n",
       "      <td>1798</td>\n",
       "      <td>175.655345</td>\n",
       "      <td>0.571708</td>\n",
       "      <td>0.876287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-16</th>\n",
       "      <td>1946</td>\n",
       "      <td>185.737813</td>\n",
       "      <td>0.890977</td>\n",
       "      <td>0.034804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-17</th>\n",
       "      <td>1841</td>\n",
       "      <td>195.231935</td>\n",
       "      <td>0.315050</td>\n",
       "      <td>0.611650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-18</th>\n",
       "      <td>1908</td>\n",
       "      <td>176.088245</td>\n",
       "      <td>0.080255</td>\n",
       "      <td>0.792700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-19</th>\n",
       "      <td>1520</td>\n",
       "      <td>209.761100</td>\n",
       "      <td>0.521306</td>\n",
       "      <td>0.865151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-20</th>\n",
       "      <td>1917</td>\n",
       "      <td>183.553215</td>\n",
       "      <td>0.183266</td>\n",
       "      <td>0.317227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-21</th>\n",
       "      <td>1939</td>\n",
       "      <td>175.619354</td>\n",
       "      <td>0.519548</td>\n",
       "      <td>0.390855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-22</th>\n",
       "      <td>1535</td>\n",
       "      <td>129.275591</td>\n",
       "      <td>0.850162</td>\n",
       "      <td>0.456176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-23</th>\n",
       "      <td>1545</td>\n",
       "      <td>182.013067</td>\n",
       "      <td>0.144060</td>\n",
       "      <td>0.413490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-24</th>\n",
       "      <td>1460</td>\n",
       "      <td>140.374342</td>\n",
       "      <td>0.536370</td>\n",
       "      <td>0.453802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-25</th>\n",
       "      <td>1668</td>\n",
       "      <td>174.354219</td>\n",
       "      <td>0.544716</td>\n",
       "      <td>0.605633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-26</th>\n",
       "      <td>1651</td>\n",
       "      <td>169.098246</td>\n",
       "      <td>0.557174</td>\n",
       "      <td>0.333120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-27</th>\n",
       "      <td>1761</td>\n",
       "      <td>184.557072</td>\n",
       "      <td>0.283328</td>\n",
       "      <td>0.114368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-28</th>\n",
       "      <td>1893</td>\n",
       "      <td>191.738759</td>\n",
       "      <td>0.869236</td>\n",
       "      <td>0.422022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-29</th>\n",
       "      <td>1803</td>\n",
       "      <td>163.526535</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.728364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-30</th>\n",
       "      <td>1654</td>\n",
       "      <td>202.618222</td>\n",
       "      <td>0.069654</td>\n",
       "      <td>0.429593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-02</th>\n",
       "      <td>1816</td>\n",
       "      <td>174.426871</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.270661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-03</th>\n",
       "      <td>1917</td>\n",
       "      <td>193.630403</td>\n",
       "      <td>0.716208</td>\n",
       "      <td>0.201830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-04</th>\n",
       "      <td>1854</td>\n",
       "      <td>184.761339</td>\n",
       "      <td>0.896328</td>\n",
       "      <td>0.813137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-05</th>\n",
       "      <td>1522</td>\n",
       "      <td>138.347871</td>\n",
       "      <td>0.403286</td>\n",
       "      <td>0.266905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-06</th>\n",
       "      <td>1623</td>\n",
       "      <td>178.275549</td>\n",
       "      <td>0.723482</td>\n",
       "      <td>0.770746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-07</th>\n",
       "      <td>1435</td>\n",
       "      <td>170.385600</td>\n",
       "      <td>0.771792</td>\n",
       "      <td>0.417217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-08</th>\n",
       "      <td>1781</td>\n",
       "      <td>174.408350</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.287427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-09</th>\n",
       "      <td>1542</td>\n",
       "      <td>178.415056</td>\n",
       "      <td>0.629779</td>\n",
       "      <td>0.845169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-10</th>\n",
       "      <td>1485</td>\n",
       "      <td>193.613489</td>\n",
       "      <td>0.732098</td>\n",
       "      <td>0.539681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-11</th>\n",
       "      <td>1822</td>\n",
       "      <td>169.128627</td>\n",
       "      <td>0.200106</td>\n",
       "      <td>0.237284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-12</th>\n",
       "      <td>1435</td>\n",
       "      <td>184.372084</td>\n",
       "      <td>0.636057</td>\n",
       "      <td>0.024717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-13</th>\n",
       "      <td>1561</td>\n",
       "      <td>209.736806</td>\n",
       "      <td>0.576632</td>\n",
       "      <td>0.384912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-14</th>\n",
       "      <td>1496</td>\n",
       "      <td>180.780881</td>\n",
       "      <td>0.071014</td>\n",
       "      <td>0.267072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-15</th>\n",
       "      <td>1820</td>\n",
       "      <td>156.904842</td>\n",
       "      <td>0.260782</td>\n",
       "      <td>0.427770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>1470</td>\n",
       "      <td>189.854241</td>\n",
       "      <td>0.762587</td>\n",
       "      <td>0.941885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-17</th>\n",
       "      <td>1737</td>\n",
       "      <td>198.164306</td>\n",
       "      <td>0.773502</td>\n",
       "      <td>0.703994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-18</th>\n",
       "      <td>1784</td>\n",
       "      <td>177.879795</td>\n",
       "      <td>0.219890</td>\n",
       "      <td>0.575979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-19</th>\n",
       "      <td>1578</td>\n",
       "      <td>185.770294</td>\n",
       "      <td>0.815309</td>\n",
       "      <td>0.708271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-20</th>\n",
       "      <td>1412</td>\n",
       "      <td>176.426288</td>\n",
       "      <td>0.308322</td>\n",
       "      <td>0.823113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-21</th>\n",
       "      <td>1981</td>\n",
       "      <td>174.266156</td>\n",
       "      <td>0.085367</td>\n",
       "      <td>0.050269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-22</th>\n",
       "      <td>1882</td>\n",
       "      <td>177.054617</td>\n",
       "      <td>0.080246</td>\n",
       "      <td>0.395607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-23</th>\n",
       "      <td>1884</td>\n",
       "      <td>152.896459</td>\n",
       "      <td>0.890951</td>\n",
       "      <td>0.209488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-24</th>\n",
       "      <td>1426</td>\n",
       "      <td>195.349826</td>\n",
       "      <td>0.966194</td>\n",
       "      <td>0.345634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-25</th>\n",
       "      <td>1651</td>\n",
       "      <td>203.464571</td>\n",
       "      <td>0.554973</td>\n",
       "      <td>0.614670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-26</th>\n",
       "      <td>1451</td>\n",
       "      <td>173.299706</td>\n",
       "      <td>0.517311</td>\n",
       "      <td>0.474015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-27</th>\n",
       "      <td>1564</td>\n",
       "      <td>155.562094</td>\n",
       "      <td>0.896532</td>\n",
       "      <td>0.452782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>1405</td>\n",
       "      <td>212.067533</td>\n",
       "      <td>0.335636</td>\n",
       "      <td>0.311454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>1749</td>\n",
       "      <td>198.951794</td>\n",
       "      <td>0.365152</td>\n",
       "      <td>0.031983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>1881</td>\n",
       "      <td>190.650842</td>\n",
       "      <td>0.417298</td>\n",
       "      <td>0.637264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>1537</td>\n",
       "      <td>212.189462</td>\n",
       "      <td>0.552715</td>\n",
       "      <td>0.215935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            calories      weight      mood     mood2\n",
       "2015-01-01      1977  174.645442  0.647517  0.137604\n",
       "2015-01-02      1805  145.583461  0.178595  0.279707\n",
       "2015-01-03      1631  194.649885  0.806383  0.804177\n",
       "2015-01-04      1932  203.070020  0.681920  0.502303\n",
       "2015-01-05      1904  174.151451  0.836023  0.245656\n",
       "2015-01-06      1912  140.845166  0.012778  0.275365\n",
       "2015-01-07      1410  182.446435  0.802674  0.514477\n",
       "2015-01-08      1452  209.108509  0.396144  0.957862\n",
       "2015-01-09      1998  164.325011  0.250750  0.406285\n",
       "2015-01-10      1573  157.392585  0.002709  0.814814\n",
       "2015-01-11      1539  195.110532  0.886354  0.275565\n",
       "2015-01-12      1493  220.320826  0.734026  0.766214\n",
       "2015-01-13      1725  165.238119  0.777186  0.394749\n",
       "2015-01-14      1832  187.827453  0.538420  0.764104\n",
       "2015-01-15      1798  175.655345  0.571708  0.876287\n",
       "2015-01-16      1946  185.737813  0.890977  0.034804\n",
       "2015-01-17      1841  195.231935  0.315050  0.611650\n",
       "2015-01-18      1908  176.088245  0.080255  0.792700\n",
       "2015-01-19      1520  209.761100  0.521306  0.865151\n",
       "2015-01-20      1917  183.553215  0.183266  0.317227\n",
       "2015-01-21      1939  175.619354  0.519548  0.390855\n",
       "2015-01-22      1535  129.275591  0.850162  0.456176\n",
       "2015-01-23      1545  182.013067  0.144060  0.413490\n",
       "2015-01-24      1460  140.374342  0.536370  0.453802\n",
       "2015-01-25      1668  174.354219  0.544716  0.605633\n",
       "2015-01-26      1651  169.098246  0.557174  0.333120\n",
       "2015-01-27      1761  184.557072  0.283328  0.114368\n",
       "2015-01-28      1893  191.738759  0.869236  0.422022\n",
       "2015-01-29      1803  163.526535  0.809375  0.728364\n",
       "2015-01-30      1654  202.618222  0.069654  0.429593\n",
       "...              ...         ...       ...       ...\n",
       "2015-12-02      1816  174.426871  0.011520  0.270661\n",
       "2015-12-03      1917  193.630403  0.716208  0.201830\n",
       "2015-12-04      1854  184.761339  0.896328  0.813137\n",
       "2015-12-05      1522  138.347871  0.403286  0.266905\n",
       "2015-12-06      1623  178.275549  0.723482  0.770746\n",
       "2015-12-07      1435  170.385600  0.771792  0.417217\n",
       "2015-12-08      1781  174.408350  0.756000  0.287427\n",
       "2015-12-09      1542  178.415056  0.629779  0.845169\n",
       "2015-12-10      1485  193.613489  0.732098  0.539681\n",
       "2015-12-11      1822  169.128627  0.200106  0.237284\n",
       "2015-12-12      1435  184.372084  0.636057  0.024717\n",
       "2015-12-13      1561  209.736806  0.576632  0.384912\n",
       "2015-12-14      1496  180.780881  0.071014  0.267072\n",
       "2015-12-15      1820  156.904842  0.260782  0.427770\n",
       "2015-12-16      1470  189.854241  0.762587  0.941885\n",
       "2015-12-17      1737  198.164306  0.773502  0.703994\n",
       "2015-12-18      1784  177.879795  0.219890  0.575979\n",
       "2015-12-19      1578  185.770294  0.815309  0.708271\n",
       "2015-12-20      1412  176.426288  0.308322  0.823113\n",
       "2015-12-21      1981  174.266156  0.085367  0.050269\n",
       "2015-12-22      1882  177.054617  0.080246  0.395607\n",
       "2015-12-23      1884  152.896459  0.890951  0.209488\n",
       "2015-12-24      1426  195.349826  0.966194  0.345634\n",
       "2015-12-25      1651  203.464571  0.554973  0.614670\n",
       "2015-12-26      1451  173.299706  0.517311  0.474015\n",
       "2015-12-27      1564  155.562094  0.896532  0.452782\n",
       "2015-12-28      1405  212.067533  0.335636  0.311454\n",
       "2015-12-29      1749  198.951794  0.365152  0.031983\n",
       "2015-12-30      1881  190.650842  0.417298  0.637264\n",
       "2015-12-31      1537  212.189462  0.552715  0.215935\n",
       "\n",
       "[365 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mood2'] = np.random.rand( len(dt_index) )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) It turns out having data points everyday is really noisy. Resample the data to monthly estimates. Use method of mean to resample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>weight</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-31</th>\n",
       "      <td>1698.774194</td>\n",
       "      <td>182.503042</td>\n",
       "      <td>0.502273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28</th>\n",
       "      <td>1744.392857</td>\n",
       "      <td>181.371289</td>\n",
       "      <td>0.545542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>1685.741935</td>\n",
       "      <td>178.786797</td>\n",
       "      <td>0.558413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-30</th>\n",
       "      <td>1701.166667</td>\n",
       "      <td>173.849017</td>\n",
       "      <td>0.473177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-31</th>\n",
       "      <td>1695.935484</td>\n",
       "      <td>180.960014</td>\n",
       "      <td>0.558906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>1721.900000</td>\n",
       "      <td>177.818953</td>\n",
       "      <td>0.511820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>1710.129032</td>\n",
       "      <td>178.977931</td>\n",
       "      <td>0.582747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-31</th>\n",
       "      <td>1697.548387</td>\n",
       "      <td>182.920907</td>\n",
       "      <td>0.483080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-30</th>\n",
       "      <td>1683.200000</td>\n",
       "      <td>181.531462</td>\n",
       "      <td>0.497172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-31</th>\n",
       "      <td>1741.419355</td>\n",
       "      <td>179.581411</td>\n",
       "      <td>0.572935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30</th>\n",
       "      <td>1696.233333</td>\n",
       "      <td>180.482656</td>\n",
       "      <td>0.484323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>1723.483871</td>\n",
       "      <td>181.940917</td>\n",
       "      <td>0.510366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               calories      weight      mood\n",
       "2015-01-31  1698.774194  182.503042  0.502273\n",
       "2015-02-28  1744.392857  181.371289  0.545542\n",
       "2015-03-31  1685.741935  178.786797  0.558413\n",
       "2015-04-30  1701.166667  173.849017  0.473177\n",
       "2015-05-31  1695.935484  180.960014  0.558906\n",
       "2015-06-30  1721.900000  177.818953  0.511820\n",
       "2015-07-31  1710.129032  178.977931  0.582747\n",
       "2015-08-31  1697.548387  182.920907  0.483080\n",
       "2015-09-30  1683.200000  181.531462  0.497172\n",
       "2015-10-31  1741.419355  179.581411  0.572935\n",
       "2015-11-30  1696.233333  180.482656  0.484323\n",
       "2015-12-31  1723.483871  181.940917  0.510366"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create dataframes using a dictionary of objects for each column. Again, the index need not be string types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting  Dataframes\n",
    "\n",
    "Subsetting dataframes works similarly to numpy, but with some additional functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_idx = pd.date_range('2015-01-01','2015-01-05',freq='d')\n",
    "df_col = ['sun','mon','tues','wed','thurs']\n",
    "df = pd.DataFrame(np.random.random((5,5)),index=df_idx, columns=df_col)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ df['sun'] > .5 ] #Subset certain rows, where the 'sun' column for that row is greater than .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[ (df['sun'] > .5) & (df['mon'] < .5) ] #multiple conditions, use tuples for each condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing functions summary\n",
    "\n",
    "Pandas Dataframes support various methods for indexing:\n",
    "\n",
    "- .iloc <- Index by integer/positional\n",
    "- .loc  <- Index by labels [can be integer labels!]\n",
    "\n",
    "- .ix   <- Supports both label and integer/positional indexing. Tries to go by label first, and then positional indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .iloc grabs by Positional indexing\n",
    "df.iloc[0] #Grab the 0th index row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iloc[0:3] #Grab the 0 to 3th index row (NON INCLUSIVE END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .iloc can grab subsets of the dataframe through slicing\n",
    "df.iloc[0:3, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .loc grabs by label\n",
    "df.loc['2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .loc can also grab slices (INCLUSIVE END)\n",
    "df.loc['2015-01-01':'2015-01-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .loc can grab subsets of the dataframe through slicing\n",
    "df.loc['2015-01-01':'2015-01-03',['mon','tues']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .ix allows for both label and positional indexing\n",
    "df.ix['2015-01-01']\n",
    "df.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .ix can also mix label and positional indexing\n",
    "df.ix[1:3,['sun','mon','thurs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about adding rows into the dataframe using `iloc`, `loc`, and `ix`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Iloc does not work. What would the index label have been for this anyway?\n",
    "df.iloc[5] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loc works as of Pandas .13\n",
    "df.loc[pd.Timestamp('2015-01-06')] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ix also works when using label.\n",
    "df.ix[pd.Timestamp('2015-01-07')] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again, even if using ix, if we pass in a positional label, wont work\n",
    "df.ix[7] = pd.Series(np.random.rand(5),index=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following two blocks are important when using integer indexes. Make sure you understand, or your code can be prone to bugs!**\n",
    "\n",
    "* When you have a pure integer based index, `loc` will look for the integer label you specify. i.e. df.loc[3] will look for the row with index label == 3.\n",
    "* When you have a pure integer based index, `iloc` will use the positional indexes you specify. i.e. df.iloc[3] will return the 4th row.\n",
    "* When you have a pure integer based index, `ix` will look for the integer label you specify. i.e. df.ix[3] will look for the row with index label == 3\n",
    "* When you have a mixed index containing integers, `ix` will use positional indexing! i.e. df.ix[3] will return the 4th row.\n",
    "\n",
    "\n",
    "More information at:\n",
    "[Good explanation for loc vs iloc vs ix](http://stackoverflow.com/questions/31593201/pandas-iloc-vs-ix-vs-loc-explanation/31593712#31593712)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.Series(1, index=[49,48,47,46,45,1,2,3,4,5])\n",
    "print df, '\\n'\n",
    "print 'Positional locate:'\n",
    "print df.iloc[:3], '\\n' #Positional locate.\n",
    "print 'Label locate:'\n",
    "print df.loc[:3], '\\n' #Label locate. Goes up to and includes label\n",
    "print 'Ix locate:'\n",
    "print df.ix[:3], '\\n'  #Tries first to do label loc.\n",
    "\n",
    "print df.iloc[:6], '\\n'\n",
    "#print df.ix[:6]   #Fails. There is no label loc\n",
    "\n",
    "#If labels, then use loc\n",
    "#If integers, then use iloc\n",
    "#Use ix when you have to mix integers and labels\n",
    "\n",
    "#When there are mixed types in the index, ix falls back to positional indexing\n",
    "df = pd.Series(1, index=['a','b','c',5,6,21])\n",
    "print df, '\\n'\n",
    "print df.ix[:5] #Falls back to positional indexing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random((3,2)),index=[100,200,300],columns=['A','B'])\n",
    "print df, '\\n'\n",
    "print df.iloc[0], '\\n'\n",
    "print df.loc[100], '\\n'\n",
    "print df.ix[0] #This wont work because the index is integer based, and ix looks for label==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "\n",
    "**1) Create a dataframe where the indexes are every day from 1/1/2015 to 1/10/2015 and the columns are `a` and `b`. Generate the datapoints randomly from your favorite random function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2) Grab the rows of the dataframe where date is between '2015-01-06' and '2015-01-09' (inclusive) using `loc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3) Grab the third through fifth rows of the dataframe (exclusive) using `iloc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Insert a row of random numbers into the data frame having date 2015-01-11. **\n",
    "\n",
    "**Hint1: If you have trouble, remember the type of the index you are inserting\n",
    "Hint2: Remember that Pandas adds rows by matching up index/column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple indexing\n",
    "Pandas allows you to have more than one set of indices or columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(np.random.randn(30,5),\n",
    "                   index=pd.date_range('2015-1-1','2017-7-1',freq='m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3['blah'] = ['b1','b2','b3']*10\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.reset_index() #Reset the index of df3, set it as a new column\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.set_index(['blah','index'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.index.names = ['blah','date']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.index #The Index type is a \"MultiIndex\" having a list of indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc['b1'] #Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc[ [pd.Timestamp('2015-01-31')]  ] #doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc[('b1','2015-01-31')] # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can address up until the left most unaddressed level\n",
    "df4 = pd.DataFrame(np.random.randn(8),index=['idx'+str(x) for x in range(8)])\n",
    "df4['foobar'] = ['foo','foo','bar','bar']*2\n",
    "df4['fahfoo'] = ['fah','bah']*4\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df4.reset_index().set_index(['fahfoo','foobar','index'])\n",
    "df4.index.names = ['fahfoo','foobar','idx3']\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.loc[ ('fah','foo') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Group By: Split-Apply-Combine\n",
    "Pandas provides for powerful aggregation within 'groups'. The process involves:\n",
    "* **Splitting** the data into groups based on criteria\n",
    "* **Applying** a function to each of the groups independently\n",
    "* **Combining** the groups back together into a dataframe\n",
    "\n",
    "The **Apply** step can be any function such as Aggregating values (mean,min,median,count,etc), Transforming values (similar to the winsorization example), or Filtration (removing data)\n",
    "\n",
    "The most similar paradigm would be SQL based statements such as:\n",
    "```\n",
    "SELECT column1, mean(column2), max(column3)\n",
    "FROM TheTable\n",
    "GROUP BY column1, column2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': ['foo','bar','foo','bar',\n",
    "                         'foo','bar','foo','foo'],\n",
    "                   'B': ['one','one','two','three',\n",
    "                         'two','two','one','three'],\n",
    "                   'C': np.random.randint(0,10,8),\n",
    "                   'D': np.random.randint(0,10,8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Groupby` objects are essentially mappings between 'groupings' and the set of indices the grouping is associated with. `Groupby` does NOT split. It just validates a correct mapping of labels to group names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('A') #groupby object. Group by the unique A's\n",
    "for name, group in grouped:\n",
    "    print \"Name:\", name\n",
    "    print \"Group:\"\n",
    "    print group, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['A','B']) # Group by unique combn of A's and B's\n",
    "for name, group in grouped:\n",
    "    print \"Name:\", name\n",
    "    print \"Group:\"\n",
    "    print group, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'Timestamp' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-57cbe999270b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Can also split on rows. You can specify your own rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Even'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Odd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Name:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brianchung/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[1;32m   3157\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m-> 3159\u001b[0;31m                        sort=sort, group_keys=group_keys, squeeze=squeeze)\n\u001b[0m\u001b[1;32m   3160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brianchung/anaconda/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brianchung/anaconda/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             grouper, exclusions, obj = _get_grouper(obj, keys, axis=axis,\n\u001b[0;32m--> 388\u001b[0;31m                                                     level=level, sort=sort)\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brianchung/anaconda/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort)\u001b[0m\n\u001b[1;32m   2156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         ping = Grouping(group_axis, gpr, obj=obj, name=name,\n\u001b[0;32m-> 2158\u001b[0;31m                         level=level, sort=sort, in_axis=in_axis)\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m         \u001b[0mgroupings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brianchung/anaconda/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, grouper, obj, name, level, sort, in_axis)\u001b[0m\n\u001b[1;32m   1983\u001b[0m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Grouper for '%s' not 1-dimensional\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1985\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1986\u001b[0m                 if not (hasattr(self.grouper, \"__len__\") and\n\u001b[1;32m   1987\u001b[0m                         len(self.grouper) == len(self.index)):\n",
      "\u001b[0;32m/Users/brianchung/anaconda/lib/python2.7/site-packages/pandas/tseries/base.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_algos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrmap_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/generated.pyx\u001b[0m in \u001b[0;36mpandas.algos.arrmap_object (pandas/algos.c:77984)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-57cbe999270b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Can also split on rows. You can specify your own rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Even'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Odd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Name:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'Timestamp' and 'int'"
     ]
    }
   ],
   "source": [
    "#Can also split on rows. You can specify your own rules\n",
    "grouped = df.groupby(lambda x: 'Even' if x%2==0 else 'Odd', axis=0)\n",
    "\n",
    "for name, group in grouped:\n",
    "    print \"Name:\", name\n",
    "    print \"Group:\"\n",
    "    print group, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.groups #Get mapping of group to the LABELS in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can also split on columns. You can specify your own rules\n",
    "def tmp(letter):\n",
    "    if letter.lower() in 'aeiou':\n",
    "        return 'vowel'\n",
    "    else:\n",
    "        return 'consonant'\n",
    "\n",
    "grouped = df.groupby(tmp, axis=1)\n",
    "grouped.get_group('consonant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.groups #Get mapping of group to the LABELS in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Another example, doing grouping on the columns\n",
    "multiIdx = pd.MultiIndex.from_tuples(    \n",
    "    list(zip(*[ ['fah','bah']*4,['foo','foo','bar','bar']*2])),\n",
    "    names=['fahbah','foobar'])\n",
    "\n",
    "df4 = pd.DataFrame({'A': np.random.randint(0,10,8),\n",
    "                    'B': np.random.randint(0,10,8)},\n",
    "                   index=multiIdx)\n",
    "\n",
    "grouped = df4.groupby(level=0)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Various descriptive stats measured on each of the groups\n",
    "grouped.all() # All of the elements are true (or coercible to true)\n",
    "grouped.any()\n",
    "grouped.count()\n",
    "grouped.count()\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can specifiy an aggregation functions\n",
    "grouped.agg(np.mean) #Specify existing functions\n",
    "\n",
    "#Or even write your own\n",
    "grouped.agg( lambda x: np.sum(x)/np.float64(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# can handle multiple aggregations on the columns through dicts\n",
    "grouped.agg({'A': ['mean','min','max'], 'B': ['count','nunique']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-aad391ad6390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#Group by 'fah' and 'bah', take all of the elements in them and zscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df4' is not defined"
     ]
    }
   ],
   "source": [
    "#you can also do in place transformations of the data\n",
    "def zScore(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "grouped = df4.groupby(level=1)\n",
    "#Group by 'fah' and 'bah', take all of the elements in them and zscore\n",
    "grouped.transform(zScore) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using transform, check that your transformation function actually returns the same number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Does not do what you think. \n",
    "#Notice that each element got of 'fah' got the same mean\n",
    "grouped.transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#apply is similar to transform, but resulting shape not necessarily same\n",
    "df4.groupby(level=0).apply(lambda x: (x.max(), x.min()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What?\n",
    "\n",
    "`apply` applies a function to each group. The sizes can be different.\n",
    "\n",
    "`agg` applies a function to each column for each group to reduce down to a single value.\n",
    "\n",
    "`transform` applies a function to each group, but the result must be the same size as that which is passed in. (ideal for: standardization, winsorization, demeaning, filling NAs with the mean etc)\n",
    "\n",
    "For more information: [Groupby](http://pandas.pydata.org/pandas-docs/stable/groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Pandas also has the ability to dynamically download datasets using the read_csv function.\n",
    "\n",
    "Download the following dataset using the following command. Note that this may take a while--you'll know if Python is still running if there is an asterisk to the left of the command\n",
    "```\n",
    "import pandas as pd\n",
    "chi = pd.read_csv('https://data.cityofchicago.org/api/views/4ijn-s7e5/rows.csv?accessType=DOWNLOAD')\n",
    "chi.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chi = pd.read_csv('https://data.cityofchicago.org/api/views/4ijn-s7e5/rows.csv?accessType=DOWNLOAD')\n",
    "chi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What is the shape of this data set? How many rows and columns are there?\n",
    "\n",
    "Hint: .info() or shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many distinct cities are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common Inspection Type? Hint: Use `groupby` and `idxmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
